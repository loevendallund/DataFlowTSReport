@article{RyderBarbara1988Idaa,
publisher = {ACM},
title = {Incremental data-flow analysis algorithms},
volume = {10},
year = {1988},
author = {Ryder, Barbara and Paull, Marvin},
address = {NEW YORK},
keywords = {Applied sciences ; Computer Science ; Computer Science, Software Engineering ; Computer science; control theory; systems ; Data-flow analysis ; elimination methods ; Exact sciences and technology ; Science & Technology ; Software ; Software engineering ; Technology},
language = {eng},
number = {1},
pages = {1-50},
abstract = {An incremental update algorithm modifies the solution of a problem that has been changed, rather than re-solving the entire problem. ACINCF and ACINCB are incremental update algorithms for forward and backward data-flow analysis, respectively, based on our equations model of Allen-Cocke interval analysis. In addition, we have studied their performance on a "nontoy" structured programming language L. Given a set of localized program changes in a program written in L, we identify a priori the nodes in its flow graph whose corresponding data-flow equations may be affected by the changes. We characterize these possibly affected nodes by their corresponding program structures and their relation to the original change sites, and do so without actually performing the incremental updates . Our results can be refined to characterize the reduced equations possibly affected if structured loop exit mechanisms are used, either singly or together, thereby relating richness of programming language usage to the ease of incremental updating.},
copyright = {Copyright 2004 Elsevier B.V., All rights reserved.},
issn = {0164-0925},
journal = {ACM transactions on programming languages and systems},
}

@inproceedings{EmamiMaryam1994Cipa,
publisher = {ACM},
series = {PLDI '94},
title = {Context-sensitive interprocedural points-to analysis in the presence of function pointers},
year = {1994},
author = {Emami, Maryam and Ghiya, Rakesh and Hendren, Laurie},
language = {eng},
pages = {242-256},
abstract = {This paper reports on the design, implementation, and empirical results of a new method for dealing with the aliasing problem in C. The method is based on approximating the points-to relationships between accessible stack locations, and can be used to generate alias pairs, or used directly for other analyses and transformations.
Our method provides context-sensitive interprocedural information based on analysis over invocation graphs that capture all calling contexts including recursive and mutually-recursive calling contexts. Furthermore, the method allows the smooth integration for handling general function pointers in C.
We illustrate the effectiveness of the method with empirical results from an implementation in the McCAT optimizing/parallelizing C compiler.},
booktitle = {Conference on Programming Language Design and Implementation: Proceedings of the ACM SIGPLAN 1994 conference on Programming language design and implementation; 20-24 June 1994},
copyright = {Copyright 2020 Elsevier B.V., All rights reserved.},
isbn = {9780897916622},
}

@article{KildallGaryA1973Auat,
title = {A unified approach to global program optimization},
year = {1973},
author = {Kildall, Gary A},
language = {eng},
abstract = {A technique is presented for global analysis of program structure in order to perform compile time
optimization of object code generated for expressions. The global expression optimization presented
includes constant propagation, common subexpression elimination, elimination of redundant register load
operations, and live expression analysis. A general purpose program flow analysis algorithm is developed
which depends upon the existence of an "optimizing function." The algorithm is defined formally using a
directed graph model of program flow structure, and is shown to be correct, Several optimizing functions
are defined which, when used in conjunction with the flow analysis algorithm, provide the various forms of
code optimization. The flow analysis algorithm is sufficiently general that additional functions can easily
be defined for other forms of global code optimization.},
copyright = {This publication is a work of the U.S. Government as defined in Title 17, United States Code, Section 101. Copyright protection is not available for this work in the United States.},
}

@inproceedings{LiangDonglin1999Eaag,
publisher = {ACM},
series = {PASTE '99},
title = {Equivalence analysis: a general technique to improve the efficiency of data-flow analyses in the presence of pointers},
year = {1999},
author = {Liang, Donglin and Harrold, Mary},
keywords = {alias analysis ; data-flow analysis},
language = {eng},
pages = {39-46},
abstract = {Existing methods to handle pointer variables during data-flow analyses can make such analyses inefficient both in time and space because the data-flow analyses must store and propagate large sets of data facts that are introduced by dereferences of pointer variable. This paper presents equivalence analysis, a general technique to improve the efficiency of data-flow analyses in the presence of pointers. The technique identifies equivalence relations among the memory locations accessed by a procedure and ensures that two equivalent memory locations share the same set of data facts in a procedure and in the procedures that are called by that procedure. Thus, a data-flow analysis needs to compute the data-flow information only for a representative memory location in an equivalence class. The data-flow information for other memory locations in the equivalence class can be derived from that of the representative memory location. Our empirical studies indicate that equivalence analysis may effectively improve the efficiency of many data-flow analyses.},
booktitle = {Proceedings of the 1999 ACM SIGPLAN-SIGSOFT workshop on program analysis for software tools and engineering},
isbn = {9781581131376},
issn = {0163-5948},
}

@article{PavlinovicZvonimir2021Dfrt,
title = {Data flow refinement type inference},
volume = {5},
year = {2021},
author = {Pavlinovic, Zvonimir and Su, Yusen and Wies, Thomas},
keywords = {abstract interpretation ; Liquid types ; refinement type inference},
language = {eng},
number = {POPL},
pages = {1-31},
abstract = {Refinement types enable lightweight verification of functional programs. Algorithms for statically inferring refinement types typically work by reduction to solving systems of constrained Horn clauses extracted from typing derivations. An example is Liquid type inference, which solves the extracted constraints using predicate abstraction. However, the reduction to constraint solving in itself already signifies an abstraction of the program semantics that affects the precision of the overall static analysis. To better understand this issue, we study the type inference problem in its entirety through the lens of abstract interpretation. We propose a new refinement type system that is parametric with the choice of the abstract domain of type refinements as well as the degree to which it tracks context-sensitive control flow information. We then derive an accompanying parametric inference algorithm as an abstract interpretation of a novel data flow semantics of functional programs. We further show that the type system is sound and complete with respect to the constructed abstract semantics. Our theoretical development reveals the key abstraction steps inherent in refinement type inference algorithms. The trade-off between precision and efficiency of these abstraction steps is controlled by the parameters of the type system. Existing refinement type systems and their respective inference algorithms, such as Liquid types, are captured by concrete parameter instantiations. We have implemented our framework in a prototype tool and evaluated it for a range of new parameter instantiations (e.g., using octagons and polyhedra for expressing type refinements). The tool compares favorably against other existing tools. Our evaluation indicates that our approach can be used to systematically construct new refinement type inference algorithms that are both robust and precise.},
copyright = {Copyright 2021 Elsevier B.V., All rights reserved.},
issn = {2475-1421},
journal = {Proceedings of ACM on programming languages},
}

@incollection{HorspoolR.Niegel2002AGAt,
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {A Graph—Free Approach to Data—Flow Analysis},
volume = {2304},
year = {2002},
author = {Horspool, R. Niegel and Hartmanis, Juris and van Leeuwen, Jan},
address = {Germany},
keywords = {Abstract Interpretation ; Applied sciences ; Basic Block ; Classical Algorithm ; Computer Science ; Computer Science, Artificial Intelligence ; Computer Science, Software Engineering ; Computer science; control theory; systems ; Exact sciences and technology ; Java Virtual Machine ; Memory Usage ; Programming languages ; Science & Technology ; Software ; Technology},
language = {eng},
pages = {46-61},
abstract = {For decades, data—flow analysis (DFA) has been done using an iterative algorithm based on graph representations of programs. For a given data—flow problem, this algorithm computes the maximum fixed point (MFP) solution. The edge structure of the graph represents possible control flows in the program. In this paper, we present a new, graph-free algorithm for computing the MFP solution. The experimental implementation of the algorithm was applied to a large set of samples. The experiments clearly show that the memory usage of our algorithm is much better: Our algorithm always reduces the amount of memory and reached improvements upto less than a tenth. In the average case, the reduction is about a third of the memory usage of the classical algorithm. In addition, the experiments showed that the runtimes are almost the same: The average speedup of the classical algorithm is only marginally greater than one.},
booktitle = {COMPILER CONSTRUCTION, PROCEEDINGS},
copyright = {Springer-Verlag Berlin Heidelberg 2002},
isbn = {3540433694},
issn = {0302-9743},
}

@inproceedings{DVNicky,
	abstract = {},
	author = {Lund, Nicky Ask},
	copyright = {},
	isbn = {},
	keywords = {Dead-value, program analyse, ReScript, Programmerings sprog, Type systemer, Dead-code, Dead Value, Dead Code, D{\o}d kode},
	language = {eng},
	pages = {},
	publisher = {},
	series = {},
	title = {Type system to determine dead value in ReScript},
	year = {2023},
}


@online{rescript_doc,
  author = {ReScript Association},
  title = {ReScript documentation},
  year = 2022,
  url = {https://rescript-lang.org/docs/manual/latest/introduction},
  urldate = {14-09-2022}
}

@online{rescript_assoc,
  author = {ReScript Association},
  title = {ReScript Association about},
  year = 2022,
  url = {https://rescript-association.org/about},
  urldate = {14-09-2022}
}

@online{rescript_rebrand,
  author = {ReScript Association},
  title = {BuckleScript and Reason Rebranding},
  year = 2020,
  url = {https://rescript-lang.org/blog/bucklescript-is-rebranding},
  urldate = {14-09-2022}
}

@online{reanalyze,
  author = {ReScript Association},
  title = {reanalyze},
  year = 2020,
  url = {https://github.com/rescript-association/reanalyze},
  urldate = {15-01-2023}
}

@online{df_implementation,
  author = {Nicky Ask Lund},
  title = {Dataflow implementation},
  year = 2023,
  url = {https://github.com/loevendallund/dataflow},
  urldate = {10-08-2023}
}

@inproceedings{DamianiFerruccio2006Dard,
	abstract = {In this paper we extend, by allowing the use of rank 2 intersection, the non-standard type assignment system for the detection and elimination of dead-code in typed functional programs presented by Coppo et al in the Static Analysis Symposium '96. The main application of this method is the optimization of programs extracted from proofs in logical frameworks, but it could be used as well in the elimination of dead-code determined by program specialization. The use of nonstandard types (also called annotated types) allows to exploit the type structure of the language for investigating program properties. Dead-code is detected via annotated type inference, which can be performed in a complete way, by reducing it to the solution of a system of inequalities between annotation variables. Even though the language considered in the paper is the simply typed λ-calculus with cartesian product, if-then-else, fixpoint, and arithmetic constants we can generalize our approach to polymorphic languages like Miranda, Haskell, and CAML.},
	author = {Damiani, Ferruccio and Prost, Frédéric},
	address = {Berlin, Heidelberg},
	booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	copyright = {Springer-Verlag Berlin Heidelberg 1998},
	isbn = {9783540651376},
	issn = {0302-9743},
	keywords = {Applied sciences ; Computer science; control theory; systems ; Exact sciences and technology ; Free Variable ; Inclusion Relation ; Inference Algorithm ; Lambda Calculus ; Language theory and syntactical analysis ; Software ; Software engineering ; Theoretical computing ; Type Inference},
	language = {eng},
	pages = {66-87},
	publisher = {Springer Berlin Heidelberg},
	series = {Lecture Notes in Computer Science},
	title = {Detecting and removing dead-code using rank 2 intersection},
	volume = {1512},
	year = {2006},
}

@article{LiuYanhongA.2003Edco,
	abstract = {This paper describes a powerful method for dead-code analysis and elimination in the presence of recursive data constructions. We describe partially dead recursive data using liveness patterns based on general regular tree grammars extended with the notion of live and dead, and we formulate the analysis as computing liveness patterns at all program points based on constraints constructed from the program and programming language semantics. The analysis yields the most precise program-based grammars that satisfy the constraints. The analysis algorithm takes cubic time in terms of the size of the program in the worst case but is very efficient in practice, as shown by our prototype implementation. The analysis results are used to identify and eliminate dead code. The framework for representing and analyzing properties of recursive data structures using general regular tree grammars applies to other analyses as well.},
	author = {Liu, Yanhong A. and Stoller, Scott D.},
	address = {AMSTERDAM},
	copyright = {2003 Elsevier Science B.V.},
	issn = {0167-6423},
	journal = {Science of computer programming},
	keywords = {Computer Science ; Computer Science, Software Engineering ; Constraints ; Dead-code elimination ; Program analysis ; Recursive data structures ; Regular-tree grammars ; Science & Technology ; Slicing ; Technology},
	language = {eng},
	number = {2},
	pages = {221-242},
	publisher = {Elsevier B.V},
	title = {Eliminating dead code on recursive data},
	volume = {47},
	year = {2003},
}

@inproceedings{XiHongwei1999Dcet,
	abstract = {Pattern matching is an important feature in various functional programming languages such as SML, Caml, Haskell, etc. In these languages, unreachable or redundant matching clauses, which can be regarded as a special form of dead code, are a rich source for program errors. Therefore, eliminating unreachable matching clauses at compile-time can significantly enhance program error detection. Furthermore, this can also lead to significantly more efficient code at run-time.
				 We present a novel approach to eliminating unreachable matching clauses through the use of the dependent type system of DML, a functional programming language that enriches ML with a restricted form of dependent types. We then prove the correctness of the approach, which consists of the major technical contribution of the paper. In addition, we demonstrate the applicability of our approach to dead code elimination through some realistic examples. This constitutes a practical application of dependent types to functional programming, and in return it provides us with further support for the methodology adopted in our research on dependent types in practical programming.},
	author = {Xi, Hongwei},
	address = {BERLIN},
	booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	copyright = {Copyright 2012 Elsevier B.V., All rights reserved.},
	isbn = {3540655271},
	issn = {0302-9743},
	keywords = {Applied sciences ; Computer Science ; Computer Science, Theory & Methods ; Computer science; control theory; systems ; Exact sciences and technology ; Science & Technology ; Software ; Software engineering ; Technology},
	language = {eng},
	pages = {228-242},
	publisher = {Springer Nature},
	series = {Lecture Notes in Computer Science},
	title = {Dead code elimination through dependent types},
	volume = {1551},
	year = {1999},
}

@inproceedings{KnoopJens1994Pdce,
	abstract = {A new aggressive algorithm for the elimination of partially dead code is presented, i.e., of code which is only dead on some program paths. Besides being more powerful than the usual approaches to dead code elimination, this algorithm is optimal in the following sense: partially dead code remaining in the resulting program cannot be eliminated without changing the branching structure or the semantics of the program, or without impairing some program executions.
	Our approach is based on techniques for partial redundancy elimination. Besides some new technical problems there is a significant difference here: partial dead code elimination introduces second order effects, which we overcome by means of exhaustive motion and elimination steps. The optimality and the uniqueness of the program obtained is proved by means of a new technique which is universally applicable and particularly useful in the case of mutually interdependent program optimizations.},
	author = {Knoop, Jens and Rüthing, Oliver and Steffen, Bernhard},
	booktitle = {Conference on Programming Language Design and Implementation: Proceedings of the ACM SIGPLAN 1994 conference on Programming language design and implementation; 20-24 June 1994},
	copyright = {Copyright 2020 Elsevier B.V., All rights reserved.},
	isbn = {9780897916622},
	keywords = {assignment motion ; bit-vector data flow analyses ; code motion ; data flow analysis ; dead code elimination ; partial redundancy elimination ; program optimization},
	language = {eng},
	pages = {147-158},
	publisher = {ACM},
	series = {PLDI '94},
	title = {Partial dead code elimination},
	year = {1994},
}

@book{NielsonFlemming1999IWoP,
	abstract = {In this book we shall introduce four of the main approaches to program analysis: Data Flow Analysis, Control Flow Analysis, Abstract Interpretation, and Type and Effect Systems. Each of Chapters 2 to 5 deals with one of these approaches to some length and generally treats the more advanced material in later sections. Throughout the book we aim at stressing the many similarities between what may at a first glance appear to be very unrelated approaches. To help getting this idea across, and to serve as a gentle introduction, this chapter treats all of-the approaches at the level of examples. The technical details are worked-out but it may be difficult to apply the techniques to related examples until some of the material of later chapters have been studied.
	Text in English.},
	author = {Nielson, Flemming and Nielson, Hanne R and Hankin, Chris},
	copyright = {APPROVED FOR PUBLIC RELEASE},
	keywords = {ABSTRACT INTERPRETATION ; Computer Programming and Software ; CONTROL FLOW ANALYSIS ; DATA FLOW ANALYSIS ; DATA PROCESSING ; DENMARK ; FOREIGN REPORTS ; PROGRAM ANALYSIS ; SOFTWARE ENGINEERING ; TYPE AND EFFECT SYSTEMS ; WORKSHOPS},
	language = {eng},
	organization = {AARHUS UNIV (DENMARK) DEPT OF COMPUTERSCIENCE},
	title = {International Workshop on Principles of Program Analysis},
	year = {1999},
}

